---
title: Parallelized Collections
layout: post
categories: spark
---

<p>

병렬수행되는 콜렉션은 드라이버 프로그램의 기존 collection에서 JavaSparkContext의 parallelize 메소드를 호출하여 작성됩니다.<br/>
콜렉션의 요소는 병렬로 수행가능한 분산 dataSet를 형성하기 위해 복사됩니다.<br/>
예를 들어, 1에서 5까지의 숫자를 보유한 병렬 컬렉션을 만드는 방법은 다음과 같습니다.<br/>

<pre><code>List<Integer> data = Arrays.asList(1, 2, 3, 4, 5);
JavaRDD<Integer> distData = sc.parallelize(data);
</code></pre>

생성된 이후, 분산 dataSet(distData)는 병렬로 처리가 가능합니다.<br/>
예를 들어, list의 모든 요소를 더하기 위해서 distData.reduce ((a, b)-> a + b)를 호출할 수 있습니다.<br/>
분산 dataSet에 대해서는 나중에 자세히 설명하도록 하겠습니다.<br/>
<br/>
병렬 컬렉션의 중요한 매개 변수 중 하나는 데이터 집합을 나누는 기준이 될 partitions의 number입니다.<br/>
Spark는 클러스터의 각 파티션에 대해 하나의 작업을 실행합니다.<br/>
일반적으로 클러스터의 각 CPU마다 2-4 개의 파티션을 적용하게 됩니다.<br/>
일반적으로 Spark는 클러스터를 기준으로 partition number를 자동으로 설정합니다.<br/>
그러나, parallelize 메소드에 두 번째 매개 변수로 전달하여 수동으로 설정할 수도 있습니다 (예 : sc.parallelize (data, 10)).<br/>
참고 : 코드의 일부 위치에서는 slice(partition의 동의어)라는 용어를 사용하여 이전 버전과의 호환성을 유지합니다.<br/>
<br/>
참조 : https://spark.apache.org/docs/2.1.1/programming-guide.html#parallelized-collections<br/>
<h3>이 문서는 개인적인 목적이나 배포하기 위해서 복사할 수 있다. 출력물이든 디지털 문서든 각 복사본에 어떤 비용도 청구할 수 없고 모든 복사본에는 이 카피라이트 문구가 있어야 한다.</h3>



</p>

