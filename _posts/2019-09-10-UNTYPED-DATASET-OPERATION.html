---
title: Untyped Dataset Operations
layout: post
categories: spark
---

<p>
DataFrames는 구조화된 데이터 조작을 위한 Scala, Java, Python, R에 대한 도메인 별 언어를 제공합니다.<br/>
<br/>
Spark 2.0에서 DataFrames는 Scala 및 Java API에서 제공되는 rows 데이터 집합입니다.<br/>
이러한 유형의 작업은 강력한 유형의 스칼라 / 자바 데이터 세트와 함께 제공되는 "유형 변환"과 달리 "비 유형 변환"이라고도합니다.<br/>
<br/>
아래에서 dataSet을 활용한 구조화된 데이터 작업의 예를 확인할 수 있습니다.<br/>

<pre><code>// col("...") is preferable to df.col("...")
import static org.apache.spark.sql.functions.col;

// Print the schema in a tree format
df.printSchema();
// root
// |-- age: long (nullable = true)
// |-- name: string (nullable = true)

// Select only the "name" column
df.select("name").show();
// +-------+
// |   name|
// +-------+
// |Michael|
// |   Andy|
// | Justin|
// +-------+

// Select everybody, but increment the age by 1
df.select(col("name"), col("age").plus(1)).show();
// +-------+---------+
// |   name|(age + 1)|
// +-------+---------+
// |Michael|     null|
// |   Andy|       31|
// | Justin|       20|
// +-------+---------+

// Select people older than 21
df.filter(col("age").gt(21)).show();
// +---+----+
// |age|name|
// +---+----+
// | 30|Andy|
// +---+----+

// Count people by age
df.groupBy("age").count().show();
// +----+-----+
// | age|count|
// +----+-----+
// |  19|    1|
// |null|    1|
// |  30|    1|
// +----+-----+
</code></pre>
<br/>
데이터 세트에서 수행 할 수있는 작업 유형의 전체 목록은 API 설명서를 참조하십시오.<br/>
<br/>
간단한 열 참조 및 표현식 외에도 데이터 집합에는 문자열 조작, 날짜 산술, 일반적인 수학 연산 등을 포함한 다양한 함수 라이브러리가 있습니다.<br/>
전체 목록은 DataFrame Function Reference에 있습니다.<br/>
<br/>
https://spark.apache.org/docs/latest/sql-getting-started.html#untyped-dataset-operations-aka-dataframe-operations
<br/>
<h3>이 문서는 개인적인 목적이나 배포하기 위해서 복사할 수 있다. 출력물이든 디지털 문서든 각 복사본에 어떤 비용도 청구할 수 없고 모든 복사본에는 이 카피라이트 문구가 있어야 한다.</h3>

</p>

