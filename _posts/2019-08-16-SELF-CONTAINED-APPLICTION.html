---
title: Self-Contained Applications
layout: post
categories: spark
---

<p>

Spark API를 사용하여 애플리케이션을 작성한다고 가정해보도록 합니다. <br/>
아래의 Java (Maven 기반)의 간단한 응용 프로그램을 살펴 보겠습니다.<br/>
<br/>
이 예제는 Maven을 사용하여 JAR을 컴파일하지만, 다른 유사한 빌드 시스템으로도 작동합니다.<br/>
<br/>
간단한 Spark 응용 프로그램 SimpleApp.java를 만들어보도록 하겠습니다.<br/>
<pre><code>
/* SimpleApp.java */
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.Dataset;

public class SimpleApp {
  public static void main(String[] args) {
    String logFile = "YOUR_SPARK_HOME/README.md"; // Should be some file on your system
    SparkSession spark = SparkSession.builder().appName("Simple Application").getOrCreate();
    Dataset<String> logData = spark.read().textFile(logFile).cache();

    long numAs = logData.filter(s -> s.contains("a")).count();
    long numBs = logData.filter(s -> s.contains("b")).count();

    System.out.println("Lines with a: " + numAs + ", lines with b: " + numBs);

    spark.stop();
  }
}
</code></pre>

이 프로그램은 Spark README에서‘a’가 포함 된 줄과 ‘b’가 포함 된 줄의 갯수를 계산합니다.<br/>
YOUR_SPARK_HOME을 실제 Spark가 설치된 위치로 바꿔야한다는 걸 명심하십시오.<br/>
Spark shell에서 자체 sparkSession을 초기화한 것과 달리,이 예제에서는 SparkSession을 프로그램의 일부로 초기화합니다.<br/>
<br/>
프로그램을 빌드하기 위해 Spark를 dependency로 갖는 Maven pom.xml 파일도 작성합니다. <br/>
Spark artifact에는 Scala 버전이 태그되어 있습니다.<br/>

<pre><code>
&lt;project&gt;
  &lt;groupId&gt;edu.berkeley&lt;/groupId&gt;
  &lt;artifactId&gt;simple-project&lt;/artifactId&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;name&gt;Simple Project&lt;/name&gt;
  &lt;packaging&gt;jar&lt;/packaging&gt;
  &lt;version&gt;1.0&lt;/version&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt; &lt;!-- Spark dependency --&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-sql_2.12&lt;/artifactId&gt;
      &lt;version&gt;2.4.3&lt;/version&gt;
      &lt;scope&gt;provided&lt;/scope&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>

우리는 표준 Maven 디렉토리 구조에 따라 이 파일들을 배치합니다:<br/>

<pre><code>
$ find .
./pom.xml
./src
./src/main
./src/main/java
./src/main/java/SimpleApp.java
</code></pre>

이제 Maven을 사용하여 응용 프로그램을 패키징하고 ./bin/spark-submit을 사용하여 응용 프로그램을 실행할 수 있습니다.<br/>

<pre><code>
# Package a JAR containing your application
$ mvn package
...
[INFO] Building jar: {..}/{..}/target/simple-project-1.0.jar

# Use spark-submit to run your application
$ YOUR_SPARK_HOME/bin/spark-submit \
  --class "SimpleApp" \
  --master local[4] \
  target/simple-project-1.0.jar
...
Lines with a: 46, Lines with b: 23
</code></pre>
<br/>
참조 : https://spark.apache.org/docs/latest/quick-start.html#self-contained-applications<br/>
<h3>이 문서는 개인적인 목적이나 배포하기 위해서 복사할 수 있다. 출력물이든 디지털 문서든 각 복사본에 어떤 비용도 청구할 수 없고 모든 복사본에는 이 카피라이트 문구가 있어야 한다.</h3>


</p>

