---
title: RDD Programming Guide Overview
layout: post
categories: spark
---

<p>

높은 수준에서, 모든 Spark 응용 프로그램은 사용자의 주요 기능을 실행하고 클러스터에서 다양한 병렬 작업을 실행하는 드라이버 프로그램으로 구성됩니다. <br/>
스파크가 제공하는 주요 개념은 RDD (Resilient Distributed Dataset)로, 클러스터 노드에서 분할되어 병렬로 작동 할 수있는 요소들의 모음입니다.<br/>
RDD는 Hadoop 파일 시스템 (또는 다른 Hadoop 지원 가능 파일 시스템)의 파일로부터 생성되거나, 드라이버 프로그램의 기존 Scala 콜렉션으로부터 변환하여 작성됩니다.<br/>
사용자는 Spark에 메모리에 RDD를 유지하도록 요청하여, 병렬 작업에서 효율적으로 재사용 할 수 있습니다.<br/>
또한, RDD는 노드 장애로부터 자동 복구됩니다.<br/>
<br/>
Spark의 두 번째 개념은 병렬 작업에 사용할 수 있는 공유 변수입니다.<br/>
기본적으로, Spark에서는 작업을 여러 노드에서 병렬로 실행할 때 각 실행에 사용될 변수를 복사하여 각 노드에 제공합니다.<br/>
하지만, 때로는 작업간 혹은 작업과 드라이버 프로그램간에 변수를 공유해야하는 경우가 있습니다.<br/>
Spark는 아래와 같이 두 가지 유형의 공유 변수를 지원합니다.<br/>
모든 노드에서 메모리에 값을 캐시하는 데 사용할 수있는 broadcast variables,<br/>
카운터 및 합계와 같이 오직 더하기 연산만 가능한 accumulators.<br/>
<br/>
참조 : https://spark.apache.org/docs/latest/rdd-programming-guide.html<br/>
<h3>이 문서는 개인적인 목적이나 배포하기 위해서 복사할 수 있다. 출력물이든 디지털 문서든 각 복사본에 어떤 비용도 청구할 수 없고 모든 복사본에는 이 카피라이트 문구가 있어야 한다.</h3>



</p>

