---
title: create first spark test
layout: post
categories: spark
---

<p>
scalatest를 이용하여, spark app을 테스트하는 예제를 작성해보도록 하겠습니다.<br/>
기본 템플릿은 이전 create first app을 참고 부탁드립니다.<br/>
기존에 만들어진 FirstApp을 기반으로, scalatest를 작성해보도록 합니다.<br/>
가장 먼저 test실행시 사용할 BaseSpec을 작성해주도록 합니다.<br/>
<br/>
- BaseSpec.scala<br/>
<pre><code>package org.shashaka.test

import org.apache.spark.sql.{SQLContext, SQLImplicits, SparkSession}
import org.scalatest.BeforeAndAfterEach
import org.scalatest.flatspec.AnyFlatSpec
import org.scalatest.matchers.should.Matchers

abstract class BaseSpec extends AnyFlatSpec with BeforeAndAfterEach with Matchers {
  var spark: SparkSession = _

  object testImplicits extends SQLImplicits with Serializable {
    protected override def _sqlContext: SQLContext = spark.sqlContext
  }

  override protected def beforeEach(): Unit = {
    super.beforeEach()

    spark = SparkSession
      .builder()
      .appName("testing")
      .master("local")
      .config("spark.driver.allowMultipleContexts", "false")
      .getOrCreate()

  }
}
</code></pre>

test code 작성시 toDF()를 사용하기 위해, 위와 같이 testImplicits를 작성해 test code에서 호출할 수 있도록 만들어줍니다.<br/>
이후, FirstAppTest를 아래와 같이 작성해주도록 합니다.<br/>
<br/>
-FirstAppTest.scala<br/>
<pre><code>package org.shashaka.test

class FirstAppTest extends BaseSpec {

  import testImplicits._

  "Well formatted strings" should "just work" in {
    val authors = Seq("shashaka,test", "testAuthor, testBook")
    val authorsDF = spark
      .sparkContext
      .parallelize(authors)
      .toDF("value")
      .selectExpr("split(value, ',') as values")
      .selectExpr("values[0] as name", "values[1] as book")

    assert(authorsDF.count() == 2)
  }
}
</code></pre>

해당 코드를 실행하면 정상적으로 테스트가 통과되는 것을 확인할 수 있습니다.<br/>
<br/>
해당 예제는 <br/>
https://github.com/FVBros/Spark-The-Definitive-Guide/tree/master/project-templates/scala<br/>
를 참고하여 작성하였습니다.<br/>


</p>

