---
title: Cluster Mode Overview
layout: post
categories: spark
---

<p>
<h3>Components</h3>

Spark 응용 프로그램은 클러스터에서 프로세스의 독립적인 집합으로 수행되며, 메인 프로그램(=드라이버 프로그램)에서 SparkContext에 의해 조율됩니다.<br/>
<br/>
특히, 클러스터에서 실행하기 위해 SparkContext는 여러 유형의 클러스터 관리자(Spark 자체 독립형 클러스터 관리자, Mesos 또는 YARN)에 연결하여 애플리케이션 간에 리소스를 할당 할 수 있습니다.<br/>
일단 연결되면 Spark는 클러스터의 노드에서 Executor를 가져옵니다.<br/>
이 Executor는 계산을 실행하고 응용 프로그램의 데이터를 저장하는 프로세스입니다.<br/>
다음으로, 애플리케이션 코드 (SparkContext에 전달 된 JAR 또는 Python 파일로 정의 됨)를 Executor로 보냅니다.<br/>
마지막으로 SparkContext는 실행할 task를 executor에 보냅니다.<br/>
<br/>
이러한 아키텍처에 대해 아래와 같이 몇 가지 유용한 정보가 있습니다.<br/>
<br/>
1. 각각의 application은 각각의 executor process를 가지게 되고, 각 process는 실행되는 동안 여러개의 스레드로 task를 실행합니다.<br/>
   이는 스케줄링 측면(각 드라이버가 자체 태스크를 스케줄 함)과 Executor 측면(다른 애플리케이션의 태스크가 다른 JVM에서 실행 됨) 모두에서 애플리케이션을 서로 분리하는 이점이 있습니다.<br/>
   그러나 이는 외부 스토리지 시스템에 데이터를 쓰지 않고 다른 Spark 응용 프로그램 (SparkContext 인스턴스)간에 데이터를 공유 할 수 없음을 의미합니다.<br/>
<br/>
2. Spark는 기본 클러스터 관리자와 무관합니다.<br/>
   Executor process를 확보하고 서로 통신할 수 있는 한 다른 애플리케이션을 지원하는 클러스터 관리자(예 : Mesos / YARN)에서도 비교적 쉽게 실행할 수 있습니다.<br/>
   <br/>
3. 드라이버 프로그램은 수명주기 동안 Executor에서 들어오는 연결을 수신하고 수락해야합니다.(예 : 네트워크 구성 섹션의 spark.driver.port 참조)<br/>
   따라서 드라이버 프로그램은 worker node에서 네트워크 주소를 지정할 수 있어야합니다.<br/>
<br/>
4. 드라이버는 클러스터에 작업을 예약해야하기 때문에 worker node와 가급적 동일한 근거리 통신망에 있어야 합니다.<br/>
   원격으로 클러스터에 요청을 보내려면 worker node에서 멀리 떨어져서 드라이버를 실행하는 것보다 근처에서 RPC를 열어 operation을 보내는 것이 좋습니다.<br/>
<br/>
<h3>Cluster Manager Types</h3>   
<br/>
이 시스템은 현재 여러 클러스터 관리자를 지원합니다.   <br/>
<br/>
* Standalone - Spark에 포함 된 간단한 클러스터 관리자로 클러스터를 쉽게 설정할 수 있습니다.<br/>
<br/>
* Apache Mesos - Hadoop MapReduce 및 서비스 응용 프로그램을 실행할 수 있는 일반적인 클러스터 관리자<br/>
   <br/>
* Hadoop YARN - Hadoop 2의 리소스 매니저<br/>
<br/>
* Kubernetes - 컨테이너화 된 응용 프로그램의 배포,확장 및 관리를 자동화하기위한 오픈 소스 시스템<br/>
<br/>
Spark 프로젝트에서 지원하지 않는 타사 프로젝트로써 클러스터 관리자인 Nomad가 있습니다.<br/>
<br/>
<h3>Submitting Applications</h3>   
<br/>
spark-submit 스크립트를 사용하여 모든 유형의 클러스터에 응용 프로그램을 제출할 수 있습니다. <br/>
<br/>
<h3>Monitoring</h3>   
<br/>
각 드라이버 프로그램에는 일반적으로 포트 4040에 웹 UI가 있으며 실행중인 작업, Executor 및 스토리지 사용에 대한 정보를 표시합니다.<br/>
이 UI에 액세스하려면 웹 브라우저에서 http : // <driver-node> : 4040으로 이동하십시오. <br/>
모니터링 안내서에는 다른 모니터링 옵션도 설명되어 있습니다.<br/>
<br/>
<h3>Job Scheduling</h3>   
<br/>
Spark는 여러 응용 프로그램(클러스터 관리자 수준에서)과 응용 프로그램 내에서(같은 SparkContext에서 여러 계산이 수행되는 경우) 자원 할당을 제어합니다.<br/>
작업 스케줄링 개요는 이를 자세히 설명합니다.<br/>
<br/>
<h3>Glossary</h3>   
<br/>
다음 표에는 클러스터 개념을 나타내는 데 사용되는 용어가 요약되어 있습니다.<br/>
<br/>
*Application<br/>
Spark 기반의 사용자 프로그램. <br/>
클러스터에서 드라이버 프로그램과 실행 프로그램으로 구성됩니다.<br/>
<br/>
*Application jar	<br/>
사용자의 Spark 애플리케이션을 포함하는 jar입니다. <br/>
경우에 따라 사용자는 응용 프로그램 및 해당 종속성을 포함하는 "uber jar"을 만들려고합니다. <br/>
사용자의 jar에는 Hadoop 또는 Spark 라이브러리가 포함되어서는 안되지만 런타임시 추가됩니다.<br/>
<br/>
*Driver program<br/>
응용 프로그램의 main() 함수를 실행하고 SparkContext를 만드는 프로세스<br/>
<br/>
*Cluster manager	<br/>
클러스터에서 리소스를 획득하기위한 외부 서비스 (예 : YARN Mesos의 독립형 관리자)<br/>
<br/>
*Deploy mode<br/>
드라이버 프로세스가 실행되는 위치를 구별합니다. <br/>
"cluster"모드에서 프레임 워크는 클러스터 내부에서 드라이버를 시작합니다. <br/>
"client"모드에서 제출자는 클러스터 외부에서 드라이버를 시작합니다.<br/>
<br/>
*Worker node	<br/>
클러스터에서 애플리케이션 코드를 실행할 수있는 모든 노드<br/>
<br/>
*Executor<br/>
Worker node에서 응용 프로그램을 위해 시작된 프로세스로서 작업을 실행하고 데이터를 메모리 또는 디스크 저장소에 보관합니다. <br/>
각 애플리케이션에는 자체 실행 프로그램이 있습니다.<br/>
<br/>
*Task<br/>
하나의 Executor에게 보내질 작업 단위<br/>
<br/>
*Job<br/>
Spark 작업 (예 : 저장, 수집)에 응답하여 생성되는 여러 작업으로 구성된 병렬 계산.<br/>
이 용어는 드라이버 로그에 사용됩니다.<br/>
<br/>
*Stage	<br/>
각 job은 작은 세트의 task들로 나뉘어지고 이를 stages라고 부릅니다.<br/>
각 stage는 서로 의존적입니다.(MapReduce의 map과 reduce의 stage와 비슷합니다.)<br/>
이 용어는 드라이버 로그에 사용됩니다.<br/>

<br/>
참조 : https://spark.apache.org/docs/latest/cluster-overview.html<br/>
<h3>이 문서는 개인적인 목적이나 배포하기 위해서 복사할 수 있다. 출력물이든 디지털 문서든 각 복사본에 어떤 비용도 청구할 수 없고 모든 복사본에는 이 카피라이트 문구가 있어야 한다.</h3>



</p>

